{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Neural Network (QNN)\n",
    "\n",
    "The key different of QNN from QSVM.Variational is as follows:\n",
    "- QSVM.Variational needs n qubits to encode n-dim datapoints\n",
    "- QNN needs log2(n) qubits to encode n-dim datapoints\n",
    "This means QNN has the potential high-dimensional datapoints with a limited number of qubits. \n",
    "\n",
    "\n",
    "### Technical design and comparison\n",
    "Below shows our proposal:\n",
    "![structure](QNN.png)\n",
    "\n",
    "Given the 4-d data point, [x1, x2, x3, x4], we use 2 qubits to encode it. For simplicity, let us assume the data point is normalized during the preprocessing. \n",
    "\n",
    "We first invoke the custom initialization algorithm, which creates the circuit that produces the amplitude vector (i.e., the normalized data point); We then apply the variational form, similar to QSVM.Variational. Lastly, we derive the cost function. The optimizer is applied to minimize the cost function. \n",
    "\n",
    "In contrast, QSVM.Varitional needs 4 qubits. Note that QSVM relies on the proper feature map, which requires some domain expertise to design. \n",
    "\n",
    "### Result\n",
    "We applied QNN and QSVM.Variational to the Wine dataset. QNN has much better accuracy (90%) than QSVM.Vartional (around 50%). Besides, QNN is 3X faster for this dataset. \n",
    "\n",
    "In the following, we will reproduce the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def Wine(training_size, test_size, n):\n",
    "    class_labels = [r'A', r'B', r'C']\n",
    "\n",
    "    data, target = datasets.load_wine(True)\n",
    "    sample_train, sample_test, label_train, label_test = train_test_split(data, target, test_size=test_size, random_state=7)\n",
    "\n",
    "    # Now we standarize for gaussian around 0 with unit variance\n",
    "    std_scale = StandardScaler().fit(sample_train)\n",
    "    sample_train = std_scale.transform(sample_train)\n",
    "    sample_test = std_scale.transform(sample_test)\n",
    "\n",
    "    # Now reduce number of features to number of qubits\n",
    "    pca = PCA(n_components=n).fit(sample_train)\n",
    "    sample_train = pca.transform(sample_train)\n",
    "    sample_test = pca.transform(sample_test)\n",
    "\n",
    "    # Scale to the range (-1,+1)\n",
    "    samples = np.append(sample_train, sample_test, axis=0)\n",
    "    minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "    sample_train = minmax_scale.transform(sample_train)\n",
    "    sample_test = minmax_scale.transform(sample_test)\n",
    "    # Pick training size number of samples from each distro\n",
    "    training_input = {key: (sample_train[label_train == k, :])[:training_size] for k, key in enumerate(class_labels)}\n",
    "    test_input = {key: (sample_train[label_train == k, :])[training_size:(\n",
    "        training_size+test_size)] for k, key in enumerate(class_labels)}\n",
    "    return sample_train, training_input, test_input, class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us import the necessary dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.aqua.input import SVMInput\n",
    "from qiskit.aqua import run_algorithm, QuantumInstance, aqua_globals\n",
    "from qiskit.aqua.algorithms import QSVMVariational\n",
    "from qiskit.aqua.components.optimizers import SPSA, COBYLA\n",
    "from qiskit.aqua.components.feature_maps import SecondOrderExpansion\n",
    "from qiskit.aqua.components.variational_forms import RYRZ, RY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run QNN against Wine dataset first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "feature_dim = 4 # dimension of each data point\n",
    "training_dataset_size = 20\n",
    "testing_dataset_size = 10\n",
    "random_seed = 10598\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "sample_Total, training_input, test_input, class_labels = Wine(training_size=training_dataset_size,\n",
    "                                                                     test_size=testing_dataset_size,\n",
    "                                                                     n=feature_dim)\n",
    "svm_input = SVMInput(training_input, test_input)\n",
    "params = {\n",
    "    'problem': {'name': 'svm_classification', 'random_seed': random_seed},\n",
    "    'algorithm': {'name': 'QNN'},\n",
    "    'backend': {'provider': 'qiskit.BasicAer', 'name': 'statevector_simulator'},\n",
    "    'optimizer': {'name': 'COBYLA', 'maxiter':200},\n",
    "    'variational_form': {'name': 'RYRZ', 'depth': 3}\n",
    "}\n",
    "result = run_algorithm(params, svm_input)\n",
    "print(\"testing accuracy: \", result['testing_accuracy'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run QSVM.Variational against Wine now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "feature_dim = 4 # dimension of each data point\n",
    "training_dataset_size = 20\n",
    "testing_dataset_size = 10\n",
    "random_seed = 10598\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "params = {\n",
    "    'problem': {'name': 'svm_classification', 'random_seed': random_seed},\n",
    "    'algorithm': {'name': 'QSVM.Variational'}, #\n",
    "    'backend': {'provider': 'qiskit.BasicAer', 'name': 'statevector_simulator'},\n",
    "    'optimizer': {'name': 'COBYLA', 'maxiter':200},\n",
    "    'variational_form': {'name': 'RYRZ', 'depth': 3}\n",
    "}\n",
    "result = run_algorithm(params, svm_input)\n",
    "print(\"testing accuracy: \", result['testing_accuracy'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:private_qnn] *",
   "language": "python",
   "name": "conda-env-private_qnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
