{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying  handwritten digits with a Quantum Support Vector Machine\n",
    "\n",
    "The goal of this notebook is to have a functioning support vector machine based on the HHL algorithm, which can decide between handwritten 6s and 9s. First two features of the image are extracted from the digit images, namely the ratio between black pixels in the upper (left) and lower (right) half of the image. So we have two coordinates to represent a handwritten digit in the 'feature space'. The SVM is supposed find an optimal fence (hyperplane), which divides the two groups. The learning of the SVM is done via the HHL algorithm, because the least-squares approximation of the optimization of the hyperplane reduces to the problem of solving a system of linear equations.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg\" width=\"300px\"/>\n",
    "\n",
    "One of the biggest drawbacks of the HHL is, that the result is encoded in a quantum state and, therefore, not directly accessible. However, the SVM only needs to classify unknown inputs into the two groups, that is telling on which side of fence the new data point lies. Thus, we can use the quantum computer as well for the classification calculation, using the quantum encoded result of the training.\n",
    "\n",
    "This whole notebook is heavily based on the work of:\n",
    "* [Li, Liu, Xu, Du: Experimental Realization of a Quantum Support Vector Machine](https://doi.org/10.1103/PhysRevLett.114.140504)\n",
    "* [Rebentrost, Mohseni, Lloyd: Quantum support vector machine for big data classification](https://doi.org/10.1103/PhysRevLett.113.130503)\n",
    "* [Harrow, Hassedim, Lloyd: Quantum algorithm for solving linear systems of equations](https://doi.org/10.1103/PhysRevLett.103.150502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ocr_prep as prep\n",
    "import svm_base as svm\n",
    "import numpy as np\n",
    "from qiskit import execute, register\n",
    "#import Qconfig\n",
    "import os\n",
    "os.system(\"./install.sh\")\n",
    "#register(Qconfig.APItoken)\n",
    "svm.MODE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "first the training data, as well as, the testing data is preprocessed, by calculating the ratios between black pixels in the upper (left) and lower (right) part of the image. Then a linear conversion happens to make them easier to use for our application and finally the vector is normalized to be representable by a qubit. The training data gets an additional label '-1' for the '6' and '1' for '9'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jan/.demo/svm/data/train9.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-efe6c2675fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#training_set = prep.get_random_set(n=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"-1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"6\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"9\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/VIRTCode/qiskit-aqua-hhl/demo/svm/ocr_prep.py\u001b[0m in \u001b[0;36mdisplay_images\u001b[0;34m(paths, size, title)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jan/.demo/svm/data/train9.png'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD8CAYAAACCaZo+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADTxJREFUeJzt3H+o3fddx/Hna71mg7kfskYZN1eXcVNrCMN1J7Ug6GAKaf9I/tiQRsac1IXhrQibQmWCUv+QOVAYqc6oY06wXbc/JOJ2i2jLQOxub91Wm5Y2Wa0m10GzbvSf4bJe3v5xT93x5p7cd5Jz7r1Jnw+4cM/3fHLO58s7PM/3nBySqkKSOl6z3RuQdO0wGJLaDIakNoMhqc1gSGozGJLaNg1Gkk8neSHJk2PuT5JPJjmT5Ikkt0x+m5o256yOzhXGZ4BDl7j/dmDf8OcY8GdXvy1tg8/gnLWJTYNRVV8Gvn2JJUeAz9aaR4E3J3nrpDaoreGc1TEzgceYBc6O3D43PPbN9QuTHGPt1YnXv/7177r55psn8PSalAMHDvDkk0+ujrnbOV8nHn/88W9V1e4r+bOTCEZbVZ0ATgAMBoNaXl7eyqfXJp5//nn27t37/at9HOe8syX5zyv9s5P4V5IVYG7k9p7hMV1fnLMmEoyTwAeGn6LfBrxUVRddpuqa55y1+VuSJPcD7wZuTHIO+D3ghwCq6lPAF4E7gDPAd4FfndZmNT1Hjx7lkUceAXitc9Y4mwajqo5ucn8BCxPbkbbF/fffD0CSf6uqwfr7nbPAb3pKugwGQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDU1gpGkkNJnklyJsk9G9z/40keTvLVJE8kuWPyW9W0LS4uAhxwzhpn02AkuQG4D7gd2A8cTbJ/3bLfBR6sqncCdwJ/OumNarpWV1dZWFgAeBbnrDE6Vxi3Ameq6rmqugA8ABxZt6aANw5/fxPw35PborbC0tIS8/PzABecs8bpBGMWODty+9zw2KjfB96f5BzwReA3NnqgJMeSLCdZPn/+/BVsV9OysrLC3Nzc6CHnrItM6kPPo8BnqmoPcAfwN0kueuyqOlFVg6oa7N69e0JPrS3knF/lOsFYAUZfevYMj426C3gQoKr+FXgdcOMkNqitMTs7y9mzoxeSzlkX6wTjMWBfkr1JdrH2YdfJdWv+C3gPQJKfYu0vktei15CDBw9y+vRpgF3OWeNsGoyqehm4G3gIeJq1T8lPJbk3yeHhso8CH0rydeB+4INVVdPatCZvZmaG48ePA9yEc9YY2a55DwaDWl5e3pbn1nhJHq+qwaQezznvPFczY7/pKanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqawUjyaEkzyQ5k+SeMWt+KclTSU4l+dvJblNbYXFxEeCAc9Y4M5stSHIDcB/wi8A54LEkJ6vqqZE1+4DfAX62qr6T5EentWFNx+rqKgsLCwDPAgOcszbQucK4FThTVc9V1QXgAeDIujUfAu6rqu8AVNULk92mpm1paYn5+XmAC85Z43SCMQucHbl9bnhs1E3ATUn+JcmjSQ5t9EBJjiVZTrJ8/vz5K9uxpmJlZYW5ubnRQ85ZF5nUh54zwD7g3cBR4C+SvHn9oqo6UVWDqhrs3r17Qk+tLeScX+U6wVgBRl969gyPjToHnKyq71fVf7D2PnjfZLaorTA7O8vZs6MXks5ZF+sE4zFgX5K9SXYBdwIn1635O9ZedUhyI2uXrs9NcJ+asoMHD3L69GmAXc5Z42wajKp6GbgbeAh4Gniwqk4luTfJ4eGyh4AXkzwFPAz8dlW9OK1Na/JmZmY4fvw4rEXAOWtDqapteeLBYFDLy8vb8twaL8njVTWY1OM5553nambsNz0ltRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1JbKxhJDiV5JsmZJPdcYt17k1SSweS2qK2yuLgIcMA5a5xNg5HkBuA+4HZgP3A0yf4N1r0B+E3gK5PepKZvdXWVhYUFgGdxzhqjc4VxK3Cmqp6rqgvAA8CRDdb9AfBx4H8muD9tkaWlJebn5wEuOGeN0wnGLHB25Pa54bH/k+QWYK6q/uFSD5TkWJLlJMvnz5+/7M1qelZWVpibmxs95Jx1kav+0DPJa4A/Bj662dqqOlFVg6oa7N69+2qfWlvIOQt6wVgBRl969gyPveINwAHgkSTPA7cBJ/1A7NoyOzvL2bOjF5LOWRebaax5DNiXZC9rf4HuBH75lTur6iXgxlduJ3kE+K2qWp7sVjVNBw8e5PTp0wC7kuzCOWsDm15hVNXLwN3AQ8DTwINVdSrJvUkOT3uD2hozMzMcP34c4Cacs8ZIVW3LEw8Gg1pe9sVpp0nyeFVN7G2Gc955rmbGftNTUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNTWCkaSQ0meSXImyT0b3P+RJE8leSLJPyX5iclvVdO2uLgIcMA5a5xNg5HkBuA+4HZgP3A0yf51y74KDKrqHcAXgD+a9EY1XaurqywsLAA8i3PWGJ0rjFuBM1X1XFVdAB4AjowuqKqHq+q7w5uPAnsmu01N29LSEvPz8wAXnLPG6QRjFjg7cvvc8Ng4dwFf2uiOJMeSLCdZPn/+fH+XmrqVlRXm5uZGDzlnXWSiH3omeT8wAD6x0f1VdaKqBlU12L179ySfWlvIOb96zTTWrACjLz17hsf+nyS/AHwM+Pmq+t5ktqetMjs7y9mzoxeSzlkX61xhPAbsS7I3yS7gTuDk6IIk7wT+HDhcVS9MfpuatoMHD3L69GmAXc5Z42wajKp6GbgbeAh4Gniwqk4luTfJ4eGyTwA/DHw+ydeSnBzzcNqhZmZmOH78OMBNOGeNkaraliceDAa1vLy8Lc+t8ZI8XlWDST2ec955rmbGftNTUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1GQxJbQZDUpvBkNRmMCS1tYKR5FCSZ5KcSXLPBve/Nsnnhvd/JcnbJr1RTd/i4iLAAeescTYNRpIbgPuA24H9wNEk+9ctuwv4TlXNA38CfHzSG9V0ra6usrCwAPAszlljdK4wbgXOVNVzVXUBeAA4sm7NEeCvh79/AXhPkkxum5q2paUl5ufnAS44Z40z01gzC5wduX0O+Jlxa6rq5SQvAW8BvjW6KMkx4Njw5veSPHklm96BbmTduV6DfgR4I/CTw9vO+WLXw5zhBzO+bJ1gTExVnQBOACRZrqrBVj7/tFwP55LkfcAh4Kev9rGc886WZPlK/2znLckKMDdye8/w2IZrkswAbwJevNJNaVs4Z22qE4zHgH1J9ibZBdwJnFy35iTwK8Pf3wf8c1XV5LapLfAYsA/Y5Zw1zqbBqKqXgbuBh4CngQer6lSSe5McHi77K+AtSc4AHwEu+ie5DZy4wj3vRNf8uYzM+cdwzuNcL+dyxecRXyAkdflNT0ltBkNS29SDcb18rbxxHh9Mcj7J14Y/v7Yd++xI8ukkL4z7fkTWfHJ4rk8kuaXxmM55B5nGjAGoqqn9ADcA3wDeDuwCvg7sX7fm14FPDX+/E/jcNPc0xfP4IHB8u/faPJ+fA24Bnhxz/x3Al4AAtwFfcc7X1pwnPeNXfqZ9hXG9fK28cx7XjKr6MvDtSyw5Any21jwKvDnJWy+x3jnvMFOYMTD9tyQbfa18dtyaWvunvVe+bryTdM4D4L3Dy7svJJnb4P5rRfd8L2e9c95ZLnfGgB96TtLfA2+rqncA/8gPXk11fXlVz3nawbhevm686XlU1YtV9b3hzb8E3rVFe5uGztwud71z3lkud8bA9INxvXytfNPzWPf+7zBr35a8Vp0EPjD8JP024KWq+uYl1jvna8/lznjNFnxaewdr/ynLN4CPDY/dCxwe/v464PPAGWAJePt2f8J8hefxh8Ap1j5Zfxi4ebv3fIlzuR/4JvB91t673gV8GPjw8P6w9p8mfQP4d2DgnK+tOU9jxlXlV8Ml9fmhp6Q2gyGpzWBIajMYktoMhqQ2gyGpzWBIavtfpaD7WCM869AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_set = [\"train9.png\", \"train6.png\"]\n",
    "training_set = list(map(lambda x: os.path.join(prep.BASE_PATH, x), training_set))\n",
    "#training_set = prep.get_random_set(n=2)\n",
    "prep.display_images(training_set, title=False)\n",
    "\n",
    "labels = {\"-1\": \"6\", \"1\": \"9\"}\n",
    "\n",
    "training_data = prep.preprocess_images(training_set, labels=[1, -1])\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set = prep.get_random_set(n=1)\n",
    "prep.display_images(test_set, title=False)\n",
    "\n",
    "test_data = prep.preprocess_images(test_set)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix generation\n",
    "\n",
    "Rebentrost et. al. state a quantum algorithm which creates the matrix on the quantum computer and directly uses is to calculate its inverse. However due to viability problems, we choose a hybrid approach like Li et al. Here the matrix is generated and then reconstructed classically using state tomography. This matrix is also calculated classically, being $K_{ij} = \\vec{x_i}\\cdot\\vec{x_j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tomo_matrix = svm._construct_density_matrix2x2(training_data)\n",
    "clas_matrix = np.array([[w[0].dot(v[0]) for w in training_data] for v in training_data])\n",
    "clas_matrix = clas_matrix/np.trace(clas_matrix)\n",
    "print(\"Construct classical matrix\")\n",
    "print(clas_matrix)\n",
    "matrix = tomo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction and execution of the circuit\n",
    "\n",
    "The HHL algorithm is being constructed here. After its execution the circuit for finding the classification of the the testing data point is appended. The probability of measuring a specific qubit in $|0\\rangle$ is then $\\frac{1}{2}(1+\\langle x | u \\rangle)$, where the sign of $\\langle x | u \\rangle$ tells us the group the input belongs to. \n",
    "\n",
    "The HHL algorithm has a probability of failing, that means the first qubit measures $|0\\rangle$. So all those counts are discarded. The difference between $|10\\rangle$ and $|11\\rangle$ should eventually give the demanded classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invec = svm.normalize([td[1] for td in training_data])\n",
    "qc = svm._construct_hhl(matrix, invec=invec, evo_time=2*np.pi)\n",
    "svm._construct_svm_expectation_value2x2(qc, training_data, test_data[0])\n",
    "print(\"b =\", invec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = execute(qc, backend=\"local_qasm_simulator\").result()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.get_counts())\n",
    "svm.plot_counts(result, [qc])\n",
    "cla = svm.classify_results(result, [qc], test_data)\n",
    "print(\"The digit is a\", labels[str(cla[0][1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk testing\n",
    "\n",
    "Here, the above code is tested far more testing samples. The upper cell generates a test_set and the lower cell classifies it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_bulk = prep.get_random_set()\n",
    "test_data_bulk = prep.preprocess_images(test_set_bulk)\n",
    "fig, axes = prep.display_images(test_set_bulk, title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = svm.classify(training_data, test_data_bulk, matrix=matrix, evo_time=2*np.pi, plot=True)\n",
    "res2 = svm.classify_classically(training_data, test_data_bulk, matrix)\n",
    "for ax, re, re2 in zip(axes, res, res2):\n",
    "    ax.set_title(\"Q: \" + labels[str(re[1])] + \"  C: \" + labels[str(re2[1])], size=18, color=\"red\" if re[1] != re2[1] else \"green\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The circuit\n",
    "\n",
    "The abstract circuit looks like this:\n",
    "\n",
    "![](img/circ/svm2.png)\n",
    "\n",
    "The operators and states are defined like $U|0\\rangle|\\vec{\\alpha}\\rangle = |u\\rangle$ and $V|0\\rangle|0\\rangle=|v\\rangle$. The angles $\\theta_i$ correspond to the feature vectors like $\\theta_i = 2\\arcsin\\frac{x_i^1}{x_i^2}$. The subscript $x$ indicates the test-vector. So the full measuring process is basically  $\\langle 00|V^{*T}|u\\rangle=\\langle v|u\\rangle$. The controlling of $V^{*T}$ gives the probabilities $P_{0/1} = \\frac{1}{2}(\\langle00|u\\rangle \\pm \\langle v|u\\rangle)$ of measuring $|0\\rangle$ ($|1\\rangle$) in the second qubit, i.e. $P_0-P_1=\\langle v|u\\rangle$. [More on theory](svm_ocr_theoretical.ipynb)\n",
    "\n",
    "The full qasm circuit is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.tools.visualization import matplotlib_circuit_drawer\n",
    "matplotlib_circuit_drawer(qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
